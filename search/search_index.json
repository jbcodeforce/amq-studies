{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AMQ Studies Apache Active MQ started in 2004 as the first open source JMS specification implementation but has evolved to a event driven architecture backbone, with peristence, massive scalability and high availability. It is a big product with a lot of features. It is now in two flavors: classic and artemis. Artemis is the new architecture. Characteristics Heterogeneous application integration Java, C/C++, .NET, Perl, PHP, Python, Ruby JMS compliant from design pub / sub and point-to-point communication style. With Topic, subscription may be durable which means they retain a copy of each message sent to the topic until the subscriber consumes them Guarantee the mesage will be delivered once and only once to each consumer of a queue or a durable topic. Support the sending and acknowledgement of multiple messages in a single local transaction Support XA transaction in Java using JTA Message can be persisted in permanent storage, and will survice server crashes and restart. Support HTTP/S via REST call, STOMP, MQTT, AMQT Provide clustering model where messages can be intelligently load balanced between the servers in the cluster, according to the number of consumers on each node, and whether they are ready for messages Architecture The following diagram illustrates the component of Active MQ Artemis architecture for a standalone broker: Each broker server is a Java POJO. Broker configuration is defined in a broker.xml file and control clustering, how to access it, and how it connect to other servers, but also its queues and topics. A broker instance, is the result of starting a broker process, and is the directory containing all the configuration and runtime data, such as logs and data files, associated with a broker process. Use persistent journal to persist messages on disk. It is possible to plug a JDBC and remote database. (This experimental) Client applications can interact with any protocol which are mapped to Core protocol. JMS API has a provider that uses the core client library. Broker always just deals with core API interactions. The normal stand-alone messaging broker configuration comprises a core messaging broker and a number of protocol managers that provide support for the various protocols Clustering It is possible to group brokers so they can share the message processing and support high availability. Each server within the cluster manages its own messages and handles its own connections. Cluster is formed by each node declaring cluster connections to other nodes in the broker.xml configuration file or by using dynamic cluster discovery using broadcast technics like UDP multicast. Cluster connections allow messages to flow between the nodes of the cluster to balance load. The connector elements specifies how the broker can be accessed. ActiveMQ uses Netty for serving different network protocols <connectors> <connector name= \"netty-connector\" > tcp://localhost:61616 </connector> </connectors> When the broker starts, it shares its connection configuration with client or other servers using a broadcast address/port defined in a broadcast-group <broadcast-groups> <broadcast-group name= \"my-broadcast-group\" > <group-address> ${udp-address:231.7.7.7} </group-address> <group-port> 9876 </group-port> <broadcast-period> 100 </broadcast-period> <connector-ref> netty-connector </connector-ref> </broadcast-group> </broadcast-groups> broadcast-period is the period in milliseconds between consecutive broadcasts. connector-ref specifies the connector and optional backup connector that will be broadcasted as data to other servers. To support dynamic server discovery each broker needs to define discovery group. A discovery group defines how connector information is received from a broadcast endpoint. The target broker keeps a list of server -> connectors to build the cluster topology dynamically. group-address: is the multicast IP address of the group to listen on. It should match the group-address in the broadcast group that you wish to listen from. refresh-timeout: is the period the discovery group waits after receiving the last broadcast from a particular server before removing that servers connector pair entry from its list. <discovery-groups> <discovery-group name= \"my-discovery-group\" > <group-address> ${udp-address:231.7.7.7} </group-address> <group-port> 9876 </group-port> <refresh-timeout> 10000 </refresh-timeout> </discovery-group> </discovery-groups> A single node can belong to multiple clusters simultaneously. Cluster connections group servers into clusters so that messages can be load balanced between the nodes of the cluster. The declaration in the broker.xml may include the following: <cluster-connections> <cluster-connection name= \"my-cluster\" > <connector-ref> netty-connector </connector-ref> <retry-interval> 500 </retry-interval> <use-duplicate-detection> true </use-duplicate-detection> <message-load-balancing> STRICT </message-load-balancing> <max-hops> 1 </max-hops> <discovery-group-ref discovery-group-name= \"my-discovery-group\" /> </cluster-connection> </cluster-connections> connector-ref is the connector which will be sent to other nodes in the cluster so they have the correct cluster topology. retry-interval determines the interval in ms between retry to connect to a failed broker. Remember there are core bridges transparently created when defining cluster connection. use-duplicate-detection helps to avoid message duplication, by adding an identificator in the message, so duplicate. message-load-balancing determines how messages will be distributed between other nodes of the cluster. It can be one of three values - OFF, STRICT, or ON_DEMAND. The forward is on the same queue as the master node. ON_DEMAND will forward only if the other broker(s) has consumers with filters matching the message to send. Finally, the discovery group is used to obtain the list of other servers in the cluster that this cluster connection will make connections to. High Availability Clustering addresses part of the high availability requirement. But the client ability to reconnect to another server transparently is also very important as well as persistence data replication. There are different master/slave or live/backup configurations: replication (both live and backup have their own message storage), or shared storage. Only persistent message data will survive failover. High availability configuration is defined as separate configuration: ha-policy . The example below demonstrate a data replication policy, where all persistent data received by the live server will be duplicated to the backup. Live server: <ha-policy> <replication> <master> <check-for-live-server> true </check-for-live-server> </master> </replication> </ha-policy> Backup server: <ha-policy> <replication> <slave> <allow-failback> true </allow-failback> </slave> </replication> </ha-policy> Backup server is operational after it finishes synchronizing the data with its live server. With colocated both brokers act as live and backup. <ha-policy> <shared-store> <colocated> <backup-port-offset> 100 </backup-port-offset> <backup-request-retries> -1 </backup-request-retries> <backup-request-retry-interval> 2000 </backup-request-retry-interval> <max-backups> 1 </max-backups> <request-backup> true </request-backup> <master> <failover-on-shutdown> true </failover-on-shutdown> </master> <slave> <failover-on-shutdown> true </failover-on-shutdown> </slave> </colocated> </shared-store> </ha-policy> When to use Active MQ Artemis For point to point communication between Java microservices or other supported programming language. To replace RPC style synchronous calls Systems that rely upon synchronous requests typically have a limited ability to scale because eventually requests will begin to back up, thereby slowing the whole system. To adopt more loosely coupling between applications Loosely coupled architectures, on the other hand, exhibit fewer dependencies, making them better at handling unforeseen changes. Not only will a change to one component in the system not ripple across the entire system, but component interaction is also dramatically simplified. Support transaction and XA transaction. When there is a strong need to do not loose data and use only once delivery semantic. To implement stateful operation for complex event processing. JMS Summary The goal of JMS is to provide a vendor neutral API for messaging in Java. It is an abstraction layer between Java class and Message Oriented Middleware. JMS client: Java application to send and receive messages. JMS producer: A client application that creates and sends JMS messages. JMS consumer: A client application that receives and processes JMS messages. JMS provider: The implementation of the JMS interfaces to integrate with a specific MOM. JMS message: carry data and meta data between clients JMS domains: styles of messaging: point-to-point and publish/subscribe. Administered objects: Preconfigured JMS objects, accessible via JNDI, contain provider configuration to be used by clients. Connection factory: Clients use a connection factory to create connections to the JMS provider. Destination: An object to which messages are addressed and sent and from which messages are received. See producer and consumer code under the examples/basicjms folder and the explanation note . Artemis Maven plugin As presented in this note the development team has provided a Maven plugin to run broker servers using maven. This is very useful for development and testing. <plugin> <groupId> org.apache.activemq </groupId> <artifactId> artemis-maven-plugin </artifactId> Each pom.xml in our examples uses this plugin. Install and configure the server mvn install Start a server Compendium Apache ActiveMQ Artemis main page ActiveMQ Artemis product documentation Netty the asynchronous event driven network application framework for protocol servers Artemis Maven plugin","title":"Introduction"},{"location":"#amq-studies","text":"Apache Active MQ started in 2004 as the first open source JMS specification implementation but has evolved to a event driven architecture backbone, with peristence, massive scalability and high availability. It is a big product with a lot of features. It is now in two flavors: classic and artemis. Artemis is the new architecture.","title":"AMQ Studies"},{"location":"#characteristics","text":"Heterogeneous application integration Java, C/C++, .NET, Perl, PHP, Python, Ruby JMS compliant from design pub / sub and point-to-point communication style. With Topic, subscription may be durable which means they retain a copy of each message sent to the topic until the subscriber consumes them Guarantee the mesage will be delivered once and only once to each consumer of a queue or a durable topic. Support the sending and acknowledgement of multiple messages in a single local transaction Support XA transaction in Java using JTA Message can be persisted in permanent storage, and will survice server crashes and restart. Support HTTP/S via REST call, STOMP, MQTT, AMQT Provide clustering model where messages can be intelligently load balanced between the servers in the cluster, according to the number of consumers on each node, and whether they are ready for messages","title":"Characteristics"},{"location":"#architecture","text":"The following diagram illustrates the component of Active MQ Artemis architecture for a standalone broker: Each broker server is a Java POJO. Broker configuration is defined in a broker.xml file and control clustering, how to access it, and how it connect to other servers, but also its queues and topics. A broker instance, is the result of starting a broker process, and is the directory containing all the configuration and runtime data, such as logs and data files, associated with a broker process. Use persistent journal to persist messages on disk. It is possible to plug a JDBC and remote database. (This experimental) Client applications can interact with any protocol which are mapped to Core protocol. JMS API has a provider that uses the core client library. Broker always just deals with core API interactions. The normal stand-alone messaging broker configuration comprises a core messaging broker and a number of protocol managers that provide support for the various protocols","title":"Architecture"},{"location":"#clustering","text":"It is possible to group brokers so they can share the message processing and support high availability. Each server within the cluster manages its own messages and handles its own connections. Cluster is formed by each node declaring cluster connections to other nodes in the broker.xml configuration file or by using dynamic cluster discovery using broadcast technics like UDP multicast. Cluster connections allow messages to flow between the nodes of the cluster to balance load. The connector elements specifies how the broker can be accessed. ActiveMQ uses Netty for serving different network protocols <connectors> <connector name= \"netty-connector\" > tcp://localhost:61616 </connector> </connectors> When the broker starts, it shares its connection configuration with client or other servers using a broadcast address/port defined in a broadcast-group <broadcast-groups> <broadcast-group name= \"my-broadcast-group\" > <group-address> ${udp-address:231.7.7.7} </group-address> <group-port> 9876 </group-port> <broadcast-period> 100 </broadcast-period> <connector-ref> netty-connector </connector-ref> </broadcast-group> </broadcast-groups> broadcast-period is the period in milliseconds between consecutive broadcasts. connector-ref specifies the connector and optional backup connector that will be broadcasted as data to other servers. To support dynamic server discovery each broker needs to define discovery group. A discovery group defines how connector information is received from a broadcast endpoint. The target broker keeps a list of server -> connectors to build the cluster topology dynamically. group-address: is the multicast IP address of the group to listen on. It should match the group-address in the broadcast group that you wish to listen from. refresh-timeout: is the period the discovery group waits after receiving the last broadcast from a particular server before removing that servers connector pair entry from its list. <discovery-groups> <discovery-group name= \"my-discovery-group\" > <group-address> ${udp-address:231.7.7.7} </group-address> <group-port> 9876 </group-port> <refresh-timeout> 10000 </refresh-timeout> </discovery-group> </discovery-groups> A single node can belong to multiple clusters simultaneously. Cluster connections group servers into clusters so that messages can be load balanced between the nodes of the cluster. The declaration in the broker.xml may include the following: <cluster-connections> <cluster-connection name= \"my-cluster\" > <connector-ref> netty-connector </connector-ref> <retry-interval> 500 </retry-interval> <use-duplicate-detection> true </use-duplicate-detection> <message-load-balancing> STRICT </message-load-balancing> <max-hops> 1 </max-hops> <discovery-group-ref discovery-group-name= \"my-discovery-group\" /> </cluster-connection> </cluster-connections> connector-ref is the connector which will be sent to other nodes in the cluster so they have the correct cluster topology. retry-interval determines the interval in ms between retry to connect to a failed broker. Remember there are core bridges transparently created when defining cluster connection. use-duplicate-detection helps to avoid message duplication, by adding an identificator in the message, so duplicate. message-load-balancing determines how messages will be distributed between other nodes of the cluster. It can be one of three values - OFF, STRICT, or ON_DEMAND. The forward is on the same queue as the master node. ON_DEMAND will forward only if the other broker(s) has consumers with filters matching the message to send. Finally, the discovery group is used to obtain the list of other servers in the cluster that this cluster connection will make connections to.","title":"Clustering"},{"location":"#high-availability","text":"Clustering addresses part of the high availability requirement. But the client ability to reconnect to another server transparently is also very important as well as persistence data replication. There are different master/slave or live/backup configurations: replication (both live and backup have their own message storage), or shared storage. Only persistent message data will survive failover. High availability configuration is defined as separate configuration: ha-policy . The example below demonstrate a data replication policy, where all persistent data received by the live server will be duplicated to the backup. Live server: <ha-policy> <replication> <master> <check-for-live-server> true </check-for-live-server> </master> </replication> </ha-policy> Backup server: <ha-policy> <replication> <slave> <allow-failback> true </allow-failback> </slave> </replication> </ha-policy> Backup server is operational after it finishes synchronizing the data with its live server. With colocated both brokers act as live and backup. <ha-policy> <shared-store> <colocated> <backup-port-offset> 100 </backup-port-offset> <backup-request-retries> -1 </backup-request-retries> <backup-request-retry-interval> 2000 </backup-request-retry-interval> <max-backups> 1 </max-backups> <request-backup> true </request-backup> <master> <failover-on-shutdown> true </failover-on-shutdown> </master> <slave> <failover-on-shutdown> true </failover-on-shutdown> </slave> </colocated> </shared-store> </ha-policy>","title":"High Availability"},{"location":"#when-to-use-active-mq-artemis","text":"For point to point communication between Java microservices or other supported programming language. To replace RPC style synchronous calls Systems that rely upon synchronous requests typically have a limited ability to scale because eventually requests will begin to back up, thereby slowing the whole system. To adopt more loosely coupling between applications Loosely coupled architectures, on the other hand, exhibit fewer dependencies, making them better at handling unforeseen changes. Not only will a change to one component in the system not ripple across the entire system, but component interaction is also dramatically simplified. Support transaction and XA transaction. When there is a strong need to do not loose data and use only once delivery semantic. To implement stateful operation for complex event processing.","title":"When to use Active MQ Artemis"},{"location":"#jms-summary","text":"The goal of JMS is to provide a vendor neutral API for messaging in Java. It is an abstraction layer between Java class and Message Oriented Middleware. JMS client: Java application to send and receive messages. JMS producer: A client application that creates and sends JMS messages. JMS consumer: A client application that receives and processes JMS messages. JMS provider: The implementation of the JMS interfaces to integrate with a specific MOM. JMS message: carry data and meta data between clients JMS domains: styles of messaging: point-to-point and publish/subscribe. Administered objects: Preconfigured JMS objects, accessible via JNDI, contain provider configuration to be used by clients. Connection factory: Clients use a connection factory to create connections to the JMS provider. Destination: An object to which messages are addressed and sent and from which messages are received. See producer and consumer code under the examples/basicjms folder and the explanation note .","title":"JMS Summary"},{"location":"#artemis-maven-plugin","text":"As presented in this note the development team has provided a Maven plugin to run broker servers using maven. This is very useful for development and testing. <plugin> <groupId> org.apache.activemq </groupId> <artifactId> artemis-maven-plugin </artifactId> Each pom.xml in our examples uses this plugin. Install and configure the server mvn install Start a server","title":"Artemis Maven plugin"},{"location":"#compendium","text":"Apache ActiveMQ Artemis main page ActiveMQ Artemis product documentation Netty the asynchronous event driven network application framework for protocol servers Artemis Maven plugin","title":"Compendium"},{"location":"amqp/","text":"Develop with AMQP http://qpid.apache.org/index.html See the AMQP, reactive library rhea project with different JavaScripts examples. [Red Hat Openshift Application Runtime(https://developers.redhat.com/products/rhoar/overview)","title":"Amqp"},{"location":"amqp/#develop-with-amqp","text":"http://qpid.apache.org/index.html See the AMQP, reactive library rhea project with different JavaScripts examples. [Red Hat Openshift Application Runtime(https://developers.redhat.com/products/rhoar/overview)","title":"Develop with AMQP"},{"location":"basicjms/","text":"Basic JMS examples Some example of the JMS consumer and producer API and implementation considerations. Pre-requisites Be sure to have access to Active MQ artemis broker, in docker or on a cluster. We are testing on local laptop ad Openshift cluster described in this note . Major JMS concepts The basic api can be summarized in the following diagram from codenotfound.com ConnectionFactory is used to create JMS connection to the provider. It needs the broker URL, username and password. Connection is the encapsulation to the TCP/IP socket between the client and the provider. Always close connection to avoid congestion on the Provider side. A session is a single-threaded context for producing and consuming messages. A session provides a transactional context with which to group a set of sends and receives into an atomic unit of work. A MessageProducer is an object that is created by a session and used for sending messages to a destination A MessageConsumer is an object that is created by a session and used for receiving messages Destination is a queue or a topic Message includes metadata. A client can have multiple connections and in a connection can have multiple sessions. Each session can have producer, consumer or both. So a client can go to different destinations: queues and topics. Test JMS 1.1 app The following steps use the code under the examples/basicjms/src/test folder and validate quickly to send and receive a text message. The integration test is TestSentTextToQueue . To run it use the maven command as: mvn exec:java -Dexec.mainClass=\"it.TestSentTextToQueue\" -Dexec.classpathScope=\"test\" Producing text message with 2.0 In JMS 1.1 producer.send() blocks until remote peer acknowledges delivery. The code in the Publisher.java class demonstrates the 1.1 API. But JMS 2.0, support asynchronous send with CompletionListener. New classes are added like JMSProducer, and JMSConsumer which are lightweight, and have operations to access message properties and to support chaining. In JMS 2.0, the JMSContext implements the AutoCloseable interface, so no need to call the close() operation, if the creation of the JMSContext is in try with resources and catch. See JMS 2.0 API specifics in this document . Vert.x","title":"JMS Basis"},{"location":"basicjms/#basic-jms-examples","text":"Some example of the JMS consumer and producer API and implementation considerations.","title":"Basic JMS examples"},{"location":"basicjms/#pre-requisites","text":"Be sure to have access to Active MQ artemis broker, in docker or on a cluster. We are testing on local laptop ad Openshift cluster described in this note .","title":"Pre-requisites"},{"location":"basicjms/#major-jms-concepts","text":"The basic api can be summarized in the following diagram from codenotfound.com ConnectionFactory is used to create JMS connection to the provider. It needs the broker URL, username and password. Connection is the encapsulation to the TCP/IP socket between the client and the provider. Always close connection to avoid congestion on the Provider side. A session is a single-threaded context for producing and consuming messages. A session provides a transactional context with which to group a set of sends and receives into an atomic unit of work. A MessageProducer is an object that is created by a session and used for sending messages to a destination A MessageConsumer is an object that is created by a session and used for receiving messages Destination is a queue or a topic Message includes metadata. A client can have multiple connections and in a connection can have multiple sessions. Each session can have producer, consumer or both. So a client can go to different destinations: queues and topics.","title":"Major JMS concepts"},{"location":"basicjms/#test-jms-11-app","text":"The following steps use the code under the examples/basicjms/src/test folder and validate quickly to send and receive a text message. The integration test is TestSentTextToQueue . To run it use the maven command as: mvn exec:java -Dexec.mainClass=\"it.TestSentTextToQueue\" -Dexec.classpathScope=\"test\"","title":"Test JMS 1.1 app"},{"location":"basicjms/#producing-text-message-with-20","text":"In JMS 1.1 producer.send() blocks until remote peer acknowledges delivery. The code in the Publisher.java class demonstrates the 1.1 API. But JMS 2.0, support asynchronous send with CompletionListener. New classes are added like JMSProducer, and JMSConsumer which are lightweight, and have operations to access message properties and to support chaining. In JMS 2.0, the JMSContext implements the AutoCloseable interface, so no need to call the close() operation, if the creation of the JMSContext is in try with resources and catch. See JMS 2.0 API specifics in this document .","title":"Producing text message with 2.0"},{"location":"basicjms/#vertx","text":"","title":"Vert.x"},{"location":"deployment/","text":"AMQ Deployments Run Active MQ Artemis locally using docker Download tar file from https://activemq.apache.org/components/artemis/download/ . Unzip and then set the $ARTEMIS_HOME environment variable to the folder containing artemis. (e.g. < somewhere>/apache-artemis-2.10.0) Clone the official docker files for ubuntu or centos from this github: https://github.com/apache/activemq-artemis . The do the steps described in this repository README. We built the centos image: docker build -f ./docker/Dockerfile-centos -t artemis-centos . Start with the command: docker run -it -p 61616:61616 -p 8161:8161 -v $ARTEMIS_HOME/instance:/var/lib/artemis-instance artemis-centos Or you can run the broker in the background using: \"/var/lib/artemis-instance/bin/artemis-service\" start _ _ _ / \\ ____| |_ ___ __ __(_) _____ / _ \\| _ \\ __|/ _ \\ \\/ | |/ __/ / ___ \\ | \\/ |_/ __/ |\\/| | |\\___ \\ /_/ \\_\\| \\__\\____|_| |_|_|/___ / Apache ActiveMQ Artemis 2.10.0 2019-09-06 16:03:45,113 INFO [org.apache.activemq.artemis.integration.bootstrap] AMQ101000: Starting ActiveMQ Artemis Server Access the ActiveMQ admin-console as usual. Just invoke http://localhost:8161/ artemis/artemis The artemis management console looks like: The next step is to test with a simple application, for that see the basicjms note or the AMQP sample here . Clustering on separate servers Running on Openshift You may follow the instructions for the last AMQ release: at the time of writing it was 7.4. The things to do: Install AMQ broker image and application templates on Openshift namespace to make them available globally. Deploy AMQ broker select a specific project create service account: echo '{\"kind\": \"ServiceAccount\", \"apiVersion\": \"v1\", \"metadata\": {\"name\": \"amq-service-account\"}}' | oc create -f - Add the view role to the service account. oc policy add-role-to-user view system:serviceaccount:amq-demo:amq-service-account Define security certificates: you need broker keystore, a client keystore, and a client truststore that includes the broker keystore. The examples below are for Java client. # Generate a self-signed certificate for the broker keystore keytool - genkey - alias broker - keyalg RSA - keystore broker . ks # Export the certificate so that it can be shared with clients: keytool - export - alias broker - keystore broker . ks - file broker_cert # Generate a self-signed certificate for the client keystore: keytool - genkey - alias client - keyalg RSA - keystore client . ks # Create a client truststore that imports the broker certificate: keytool - import - alias broker - keystore client . ts - file broker_cert # Export the client\u2019s certificate from the keystore: keytool - export - alias client - keystore client . ks - file client_cert # Import the client\u2019s exported certificate into a broker SERVER truststore: keytool - import - alias client - keystore broker . ts - file client_cert Use the broker keystore file to create the AMQ Broker secret oc create secret generic amq-app-secret --from-file=broker.ks # Add the secret to the service account created earlier: oc secrets add sa/amq-service-account secret/amq-app-secret Create a new broker application, based on the template for a basic broker oc new-app amq-broker-74-basic -p AMQ_PROTOCOL=openwire,amqp,stomp,mqtt,hornetq -p AMQ_USER=amquser -pAMQ_PASSWORD=password -p AMQ_QUEUES=demoQueue -p AMQ_ADDRESSES=demoTopic which create brokers with the different protocols. The URL end point is defined as a new route and with different service endpoints. The URL is something like http://console-greencompute.apps.green-with-envy.ocp.csplab.local/ which needs to be known in your DNS or /etc/hosts. The different protocol end points are visible with oc status svc/broker-amq-mqtt - 172.30.205.38:1883 svc/broker-amq-stomp - 172.30.128.123:61613 svc/broker-amq-tcp - 172.30.153.208:61616 svc/broker-amq-amqp - 172.30.227.85:5672 Once deployed the console presents the queue and topic configuration: Create a SSL route to allow inbound traffic to AMQ broker using SSL. Deploying a cluster on openshift The instructions are detailed in section 8.3 of this note ,","title":"Deployments"},{"location":"deployment/#amq-deployments","text":"","title":"AMQ Deployments"},{"location":"deployment/#run-active-mq-artemis-locally-using-docker","text":"Download tar file from https://activemq.apache.org/components/artemis/download/ . Unzip and then set the $ARTEMIS_HOME environment variable to the folder containing artemis. (e.g. < somewhere>/apache-artemis-2.10.0) Clone the official docker files for ubuntu or centos from this github: https://github.com/apache/activemq-artemis . The do the steps described in this repository README. We built the centos image: docker build -f ./docker/Dockerfile-centos -t artemis-centos . Start with the command: docker run -it -p 61616:61616 -p 8161:8161 -v $ARTEMIS_HOME/instance:/var/lib/artemis-instance artemis-centos Or you can run the broker in the background using: \"/var/lib/artemis-instance/bin/artemis-service\" start _ _ _ / \\ ____| |_ ___ __ __(_) _____ / _ \\| _ \\ __|/ _ \\ \\/ | |/ __/ / ___ \\ | \\/ |_/ __/ |\\/| | |\\___ \\ /_/ \\_\\| \\__\\____|_| |_|_|/___ / Apache ActiveMQ Artemis 2.10.0 2019-09-06 16:03:45,113 INFO [org.apache.activemq.artemis.integration.bootstrap] AMQ101000: Starting ActiveMQ Artemis Server Access the ActiveMQ admin-console as usual. Just invoke http://localhost:8161/ artemis/artemis The artemis management console looks like: The next step is to test with a simple application, for that see the basicjms note or the AMQP sample here .","title":"Run Active MQ Artemis locally using docker"},{"location":"deployment/#clustering-on-separate-servers","text":"","title":"Clustering on separate servers"},{"location":"deployment/#running-on-openshift","text":"You may follow the instructions for the last AMQ release: at the time of writing it was 7.4. The things to do: Install AMQ broker image and application templates on Openshift namespace to make them available globally. Deploy AMQ broker select a specific project create service account: echo '{\"kind\": \"ServiceAccount\", \"apiVersion\": \"v1\", \"metadata\": {\"name\": \"amq-service-account\"}}' | oc create -f - Add the view role to the service account. oc policy add-role-to-user view system:serviceaccount:amq-demo:amq-service-account Define security certificates: you need broker keystore, a client keystore, and a client truststore that includes the broker keystore. The examples below are for Java client. # Generate a self-signed certificate for the broker keystore keytool - genkey - alias broker - keyalg RSA - keystore broker . ks # Export the certificate so that it can be shared with clients: keytool - export - alias broker - keystore broker . ks - file broker_cert # Generate a self-signed certificate for the client keystore: keytool - genkey - alias client - keyalg RSA - keystore client . ks # Create a client truststore that imports the broker certificate: keytool - import - alias broker - keystore client . ts - file broker_cert # Export the client\u2019s certificate from the keystore: keytool - export - alias client - keystore client . ks - file client_cert # Import the client\u2019s exported certificate into a broker SERVER truststore: keytool - import - alias client - keystore broker . ts - file client_cert Use the broker keystore file to create the AMQ Broker secret oc create secret generic amq-app-secret --from-file=broker.ks # Add the secret to the service account created earlier: oc secrets add sa/amq-service-account secret/amq-app-secret Create a new broker application, based on the template for a basic broker oc new-app amq-broker-74-basic -p AMQ_PROTOCOL=openwire,amqp,stomp,mqtt,hornetq -p AMQ_USER=amquser -pAMQ_PASSWORD=password -p AMQ_QUEUES=demoQueue -p AMQ_ADDRESSES=demoTopic which create brokers with the different protocols. The URL end point is defined as a new route and with different service endpoints. The URL is something like http://console-greencompute.apps.green-with-envy.ocp.csplab.local/ which needs to be known in your DNS or /etc/hosts. The different protocol end points are visible with oc status svc/broker-amq-mqtt - 172.30.205.38:1883 svc/broker-amq-stomp - 172.30.128.123:61613 svc/broker-amq-tcp - 172.30.153.208:61616 svc/broker-amq-amqp - 172.30.227.85:5672 Once deployed the console presents the queue and topic configuration: Create a SSL route to allow inbound traffic to AMQ broker using SSL.","title":"Running on Openshift"},{"location":"deployment/#deploying-a-cluster-on-openshift","text":"The instructions are detailed in section 8.3 of this note ,","title":"Deploying a cluster on openshift"}]}